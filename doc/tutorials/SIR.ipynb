{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling pandemics using compartmental models\n",
    "\n",
    "Coronavirus COVID-19 is a pandemic that is spreading quickly worlwide. Up to the 29th of March, there are 666,211 cases confirmed, 30,864 deaths and 141,789 recovered people worldwide. Governments and citizens are taking quick decisions to limit the spread of the virus and minimize the number of infected and deaths. These decisions are taken based on the experts opinion, which justify their claims based in the results of predictive models.\n",
    "\n",
    "\n",
    "This Jupyter Notebook is an effort to decrease the access barriers to state of the art yet simple models that can be used to take public policy decisions to limit disease spread and save lives. \n",
    "\n",
    "## SIR model\n",
    "\n",
    "Most epidemic models share a common approach on modelling the spread of a disease. The SIR model is a simple deterministic compartmental model to predict disease spread. An objective population is divided in three groups: the susceptible ($S$), the infected ($I$) and the recovered or removed ($R$). These quantities enter the model as fractions of the total population $P$:\n",
    "\n",
    "\n",
    "$$ S = \\frac{\\text{Number of susceptible individuals}}{\\text{Population size}}$$\n",
    "\n",
    "$$ I = \\frac{\\text{Number of infected individuals}}{\\text{Population size}}$$\n",
    "\n",
    "$$ R = \\frac{\\text{Number of recovered or removed individuals}}{\\text{Population size}}$$\n",
    "\n",
    "As a pandemics infects and kills much more quickly than human natural rates of birth and death, the population size is assumed constant except for the individuals that recover or die. Hence, $S+I+R=P/P=1$. The pandemics dynamics is modelled as a system of ordinary differential equations which governs the rate of change at which the percentage of susceptible, infected and recovered/removed individuals in a population evolve.\n",
    "\n",
    "The number of possible transmissions is proportional to the number of interactions between the susceptible and infected populations, `$S \\times I $`:\n",
    "\n",
    "$$\\frac{dS}{dt} = -\\alpha SI.$$\n",
    "\n",
    "Where $\\alpha$ is the reproduction rate of the process which quantifies how many of the interactions between susceptible and infected populations yield to new infections per day.\n",
    "\n",
    "The population of infected individuals will increase with new infections and decrease with recovered or removed people. \n",
    "\n",
    "$$\\frac{dI}{dt} = \\alpha S I  - \\beta I, $$\n",
    "$$\\frac{dR}{dt} = \\beta I. $$\n",
    "\n",
    "Where `$ \\beta $` is the percentage of the infected population that is removed from the transmission process per day.\n",
    "\n",
    "In early stages of the infection, the number of infected people is much lower than the susceptible populations. Hence, $S \\approx 1$ making $dI/dt$ linear and the system has the analytical solution $I(t) = I_0 \\exp (\\alpha - \\beta)t$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical implementation - SIR model\n",
    "\n",
    "Three python packages are imported: numpy for numerical computing, matplotlib.pyplot for visualization and the numerical integration routine odeint from scipy.integrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numerical computing\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "from scipy.integrate import odeint # ODE system numerical integrator\n",
    "from scipy.optimize import curve_fit # Minimize squared errors using LM method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing systems of ordinary differential equations (ODEs) in python is straightforward. First, a function is created to represent the system inputs and outputs. The inputs of the function are a vector of state variables ${\\vec{w}}$, the independent variable $t$ and a vector of parameters $\\vec{p}$. The output of the function must be the right hand side of the ODE system as a list.\n",
    "\n",
    "Following this approach, the SIR model can be implemented as it follows:\n",
    "\n",
    "$$\\vec{w} = [S,I,R]$$\n",
    "$$\\vec{p} = [\\alpha, \\beta] $$\n",
    "\n",
    "And $t$ enters directly. The function return will be the list of ODEs.\n",
    "\n",
    "$$\\vec{f} = \\left[ \\frac{dS}{dt}, \\frac{dI}{dt}, \\frac{dR}{dt} \\right]$$\n",
    "\n",
    "So $\\vec{f} = \\text{sir}(\\vec{w}, t, \\vec{p})$.\n",
    "\n",
    "The solution of this system is a vector field $\\vec{w} = [S(t),I(t),R(t)]$. In day to day words, it gives the percentage of the population who are susceptible (S), infected (I) and recovered or removed R(t) as a function of time. There is no analytical solution for this system. However, a numerical solution can be obtained using a numerical integrator. In this implementation, the function scipy.odeint is used to integrate the differential system. The ODE system of the SIR model was implemented in the function sirx(t,w,p) on the module model.py. The solver is implemented in the function _solve on the module model.py.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIR-X model\n",
    "\n",
    "A new epidemic model based in SIR, SIRX, was developed by the [Robert Koch Institut](http://rocs.hu-berlin.de/corona/docs/forecast/model/#sir-x-dynamics-outbreaks-with-temporally-increasing-interventions) and is implemented in what follows. A full description of the model is available in the [Robert Koch Institut SIRX model webiste](http://rocs.hu-berlin.de/corona/docs/forecast/model/#sir-x-dynamics-outbreaks-with-temporally-increasing-interventions).\n",
    "\n",
    "The ODE system of the SIR-X model was implemented in the function sirx(t,w,p) on the module model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example\n",
    "\n",
    "\n",
    "\n",
    "### Case study\n",
    "\n",
    "The borough of Ealing, in London, is selected arbitrarly as one of the authors is living there at the moment. According to the UK office for National Statistics, the population of Ealing by mid-year 2018 is [342,000](https://www.ealing.gov.uk/info/201048/ealing_facts_and_figures/2184/population_and_households/1). The number of reported infections at 29/03/2020 is 241.\n",
    "\n",
    "### Model parameters\n",
    "As an implementation examples, the parameter $\\beta$ is estimated from the methodology followed by the [Robert Koch Institut SIRX model webiste](http://rocs.hu-berlin.de/corona/docs/forecast/model/#sir-x-dynamics-outbreaks-with-temporally-increasing-interventions). The institute estimated the a removal rate value $\\beta = 0.38/d$ (mean infections time $T_I = 1/\\beta = 2.6d)$ based on one third of the reported average infections preioud of moderate cases in Mainland China.\n",
    "\n",
    "The reproduction number is fixed $R_0 = \\alpha / \\beta = 2.5$ as a first approximation. \n",
    "\n",
    "Please note that the predictions of this model shouldn't be taken in consideratin, as the SIR model doesn't consider dynamic variation of model parameters, which is observed in reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution and implementation\n",
    "The aim of this API is to provide an user friendly approach to build a SIR model and fit it to a target dataset in order to make predictions in few lines of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Ealing as an example to determine model initial conditions\n",
    "# Input data must be np.array\n",
    "Ealing_data = np.array([8, 18, 20, 28, 31, 42, 53, 54, 80, 97, 106, 123, 136, 165, 209, 241]) # N_of infected\n",
    "\n",
    "P_Ealing = 342000 # Ealing population ONS 2018 mid year\n",
    "I_Ealing = 8      # Infected people at 14/03/2020\n",
    "R_Ealing = 0      # Recovered people at 29/03/2020\n",
    "n_days = len(Ealing_data)\n",
    "\n",
    "# Input parameters\n",
    "beta = 0.38 # Per day\n",
    "alpha = 2.5 * beta # WHO estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate model parameters and initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate initial conditions in terms of total number of individuals\n",
    "S0 = (P_Ealing-I_Ealing)\n",
    "I0 = I_Ealing\n",
    "R0 = R_Ealing    # Recovered people\n",
    "\n",
    "# Construct vector of parameters\n",
    "params = [alpha, beta]\n",
    "\n",
    "# Construct vector of initial conditions\n",
    "w0 = [S0, I0, R0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model with the default parameters and predict the number of susceptible, infected and recovered people in the Ealing borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines are required only if opensir wasn't installed using pip install, or if opensir is running in the pipenv virtual environment\n",
    "import sys\n",
    "path_opensir = '../../'\n",
    "sys.path.append(path_opensir)\n",
    "\n",
    "# Import SIR and SIRX models\n",
    "from opensir.models import SIR, SIRX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an emplty SIR model\n",
    "my_SIR = SIR()\n",
    "# Set model parameters\n",
    "my_SIR.set_params(p=params,initial_conds=w0)\n",
    "\n",
    "# Call model.solve functions with the time in days and the number of points\n",
    "# as the number of days\n",
    "my_SIR.solve(n_days-1, n_days)\n",
    "# Unpack the numerical solution using the model.fetch() method\n",
    "sol = my_SIR.fetch()\n",
    "# Unpack the numerical solution for the susceptible (S), infected (I) and recovered or removed (R)\n",
    "S_sir = sol[:,1]\n",
    "I_sir = sol[:,2]\n",
    "R_sir = sol[:,3]\n",
    "# Plot the results\n",
    "# Define array of days. Note that the initial day is the day \"zero\", so \n",
    "# the final day is the number of days minus one. This is divided in n_days\n",
    "# intervals to be consistent with the input\n",
    "days_list = np.linspace(0, n_days-1, n_days)\n",
    "plt.plot(days_list, I_sir)\n",
    "plt.plot(days_list, Ealing_data,'bo')\n",
    "plt.show()\n",
    "my_SIR.r0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the default parameters are used, the results are completely unreliable. Indeed, the model predicts more than 150 times more people infected. This is why a model shouldn't be used blindly, and always the parameters must be checked. In UK, Social distancing started voluntarily on the 16th of February, and the lockdown started on the 23rd of February. The effect of this policy change in terms of our model, is a decrease in the reproduction rate $R_0 = \\alpha / \\beta$. As the national health system (NHS) of UK didn't reach full capacity on the period between the 15th and the 29th of March, it is reasonable to assume that the main change occured owing to a decrease in the transmission rate $\\alpha$.\n",
    "\n",
    "To obtain a more realistic approximation, the parameter can be modified to better reproduce the observed data. This process is named **parameter fitting** and it is widely used not only on epidemiology, but in any discipline which uses mathematical models to make prediction. \n",
    "\n",
    "\n",
    "The function model.fit() enables to fit the desired parameters to a certain dataset. The parameter fitting is straightforward using open-sir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Fitting \n",
    "Fitting $R_0$ through $\\alpha$ keeping $\\beta$ constant\n",
    "\n",
    "In the following case study, $R_0$ will be fitted to minimize the mean squared error between the model predictions and UK historical data on the Ealing borough in the time period between the 15th and the 29th of March of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SIR with default parameters\n",
    "my_SIR_fitted = SIR()\n",
    "my_SIR_fitted.set_params(params,w0)\n",
    "\n",
    "# Fit parameters\n",
    "w = my_SIR_fitted.fit(days_list, Ealing_data, fit_index=[True,False])\n",
    "# Print the fitted reproduction rate\n",
    "print(\"Fitted reproduction rate R_0 = %.2f\" % my_SIR_fitted.r0)\n",
    "# Build the new solution\n",
    "my_SIR_fitted.solve(n_days-1, n_days)\n",
    "# Extract solution\n",
    "sol = my_SIR_fitted.fetch()\n",
    "# Plot the results\n",
    "\n",
    "plt.plot(days_list,sol[:,2])\n",
    "plt.plot(days_list,Ealing_data,'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ealing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANGER ZONE\n",
    "\n",
    "This is extremely dangerous as $R_0$ is extremely likely to change with time. However we have seen many people taking decisions in this kind of analysis. Use it at your own risk and with a metric ton of salt.\n",
    "\n",
    "### Example: predict the total number of infections and the time where the number of infected people is maximum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_term_days = 90\n",
    "# Convert into seconds\n",
    "tf_long = long_term_days-1\n",
    "sol_long = my_SIR_fitted.solve(tf_long, long_term_days).fetch()\n",
    "N_S_long = sol_long[:,1]\n",
    "N_I_long = sol_long[:,2]\n",
    "N_R_long = sol_long[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of susceptible, infected and recovered in a two months period\n",
    "tspan_long = np.linspace(0,tf_long,long_term_days)\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(tspan_long,N_S_long)\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel(\"Number of people\")\n",
    "plt.title(\"Susceptible\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(tspan_long,N_I_long)\n",
    "plt.xlabel('Days')\n",
    "plt.title(\"Infected\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(tspan_long,N_R_long)\n",
    "plt.title(\"Recovered or removed\")\n",
    "plt.xlabel('Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the SIR model reproduces the all familiar infection bell, as well as the evolution of susceptible and recovered population. It is interesting to observe that if no measures are taken in a $R_0 = 1.47$ scenario, 65% of the Ealing population would be infected in three months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity to $R_0$\n",
    "\n",
    "A known weakness of all pandemics prediction model is the sensitivity to their parameters. In the following case study, $R_0$ will be fitted to minimize the mean squared error between the model predictions and UK historical data on the Ealing borough in the time period between the 15th and the 29th of March of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_infections(model, tf, numpoints, alpha_list=2.5, abserr=1e-8, relerr=1e-6):\n",
    "    \"\"\" compare_infections compare SIR model predictions against\n",
    "    a list of alpha values\n",
    "    \n",
    "    Inputs:\n",
    "    w0: Initial conditions\n",
    "    t: Time vector /\n",
    "    alpha_list: list or numpy array of values of alpha to be tested\n",
    "    \n",
    "    Outputs:\n",
    "    S_list: List of predictions for the fraction of susceptible population for each alpha\n",
    "    I_list: List of predictions for the fraction of infected population for each alpha\n",
    "    R_list: List of predictions for the fraction of recovered/removed population for each alpha\n",
    "    \"\"\"\n",
    "    S_list = []\n",
    "    I_list = []\n",
    "    R_list = []\n",
    "    \n",
    "    for i in alpha_list:\n",
    "        # Update parameter list\n",
    "        model.p[0] = i\n",
    "        wsol=model.solve(tf,numpoints).fetch()\n",
    "        S_list.append(wsol[:,1])\n",
    "        I_list.append(wsol[:,2])\n",
    "        R_list.append(wsol[:,3]) \n",
    "    return S_list, I_list, R_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Generate predictions for each alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = beta*np.array([1.5,1.6,1.7])\n",
    "S_list, I_list, R_list = compare_infections(my_SIR, tf_long, long_term_days, alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['r','b','k']\n",
    "plt.figure(figsize=[15,5])\n",
    "for i in range(len(S_list)):\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(tspan_long,S_list[i], col[i]+\"--\")\n",
    "    plt.legend(['R_0 = 1.5','R_0 = 1.6','R_0 = 1.7']) \n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Fraction of population')\n",
    "    plt.title('S')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(tspan_long,I_list[i], col[i])\n",
    "    plt.legend(['R_0 = 1.5','R_0 = 1.6','R_0 = 1.7']) \n",
    "    plt.xlabel('Days')\n",
    "    plt.title('I')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(tspan_long,R_list[i], col[i]+\"-.\")\n",
    "    plt.legend(['R_0 = 1.5','R_0 = 1.6','R_0 = 1.7']) \n",
    "    plt.xlabel('Days')\n",
    "    plt.title('R')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that a change as little as 6% in the reproduction rate, can change dramatically the dynamic of the pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Fit R_0 for UK values\n",
    "[sourced from UK Arcgis](https://www.arcgis.com/apps/opsdashboard/index.html#/f94c3c90da5b4e9f9a0b19484dd4bb14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_UK = 67886011\n",
    "# Data up to 28th of March\n",
    "I_UK= np.array([3269, 3983, 5018, 5683, 6650, 8077, 9529, 11658, 14543, 17089])\n",
    "n_days = len(I_UK) # Final day\n",
    "t_d = np.linspace(0,n_days-1,n_days)\n",
    "\n",
    "n_S0 = P_UK-I_UK[0]\n",
    "n_I0 = I_UK[0]\n",
    "n_R0 = 0\n",
    "n0_UK = [n_S0, n_I0, n_R0]\n",
    "p = [alpha,beta]\n",
    "\n",
    "# Create empty model\n",
    "SIR_UK = SIR()\n",
    "SIR_UK.set_params(p,n0_UK)\n",
    "# Train model\n",
    "SIR_UK.fit(t_d, I_UK)\n",
    "# Build numerical solution\n",
    "I_opt = SIR_UK.solve(n_days-1,n_days).fetch()[:,2]\n",
    "# lag = 6\n",
    "\n",
    "R_opt = SIR_UK.r0 # \n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "plt.plot(t_d,I_UK,'o')\n",
    "plt.plot(t_d, I_opt)\n",
    "plt.legend([\"UK Data\",\"SIR, $R_{0,opt}$ = %.2f\"%R_opt])\n",
    "plt.title(\"Fitting of the SIR model against 15 days of UK data\")\n",
    "plt.ylabel(\"Number of people infected\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.xlim([min(t_d),max(t_d)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = sum(np.sqrt((I_opt-I_UK)**2))/len(I_UK)        \n",
    "print(\"Mean squared error on the model in the train dataset %.2f\" % MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error calculated above indicates the average error difference between the model fitting and the train data. It is a measure of wellness of fit, but it doesn't provide information about how accurately the model predicts the number of infected.\n",
    "\n",
    "The error in the future predictions can be estimating through confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making out of sample predictions using the `model.predict` function\n",
    "\n",
    "The `model.predict` function allows out of sample predictions. It recieves one mandatory parameter, n_days, and two optional parameters. The two optional parameters are the observed number of infected (`n_I`) and the number of recovered (`n_R`) individuals. If `n_I` is not provided, the last value of the train set is used, while if `n_R` is not provided it is estimated from the fitted SIR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the results 7 days after the train data ends\n",
    "pred_7 = SIR_UK.predict(7)\n",
    "print('T n_S \\t   n_I\\t n_R')\n",
    "for i in pred_7:\n",
    "    print(*i.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions\n",
    "\n",
    "Predict the next seven days of the spread of COVID-19 in the UK, considering the 29th of March as the last day of the sample data on which the SIR model was fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime # Import datetime module from the standard library\n",
    "# Create a date time range based on the number of rows of the prediction\n",
    "numdays = pred_7.shape[0] \n",
    "day_zero = datetime.datetime(2020,3,29)\n",
    "date_list = [day_zero + datetime.timedelta(days=x) for x in range(numdays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract figure and axes\n",
    "fig, ax = plt.subplots(figsize=[5,5])\n",
    "# plt.plot(pred_7[:,0], pred_7[:,2], linewidth=2)\n",
    "plt.plot(date_list, pred_7[:,2], linewidth=2)\n",
    "plt.title('Prediction of UK Cases', size=14)\n",
    "plt.ylabel('Number of infected', size=14)\n",
    "# Remove trailing space\n",
    "plt.xlim(date_list[0],date_list[-1])\n",
    "# Limit the amount of data displayed\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "# Increase the size of the ticks\n",
    "ax.tick_params(labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confidence interval through random bootstrap\n",
    "# Define bootstrap options\n",
    "options = {\"alpha\":0.95, \"n_iter\":1000, \"r0_ci\":True}\n",
    "# Call bootstrap\n",
    "par_ci, par_list = SIR_UK.ci_bootstrap(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confidence intervals of alpha, beta and R_0\")\n",
    "print(par_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_min = par_ci[0][0]\n",
    "alpha_max = par_ci[0][1]\n",
    "# Explore the confidence intervals\n",
    "print(\"IC 95% for alpha:\", par_ci[0])\n",
    "print(\"IC 95% for beta:\", par_ci[1])\n",
    "print(\"IC 95% for r0:\", par_ci[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of confidence intervals\n",
    "\n",
    "After 1000 of random sampling of the train data, it is possible to visualize the range of predictions produced within the 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build numerical solution\n",
    "# I_opt = SIR_UK.solve(n_days-1, n_days).fetch()[:,2]\n",
    "beta_0 = SIR_UK.p[1]\n",
    "SIR_minus = SIR().set_params([alpha_min, beta_0],n0_UK)\n",
    "SIR_plus = SIR().set_params([alpha_max, beta_0],n0_UK)\n",
    "I_minus = SIR_minus.solve(n_days-1, n_days).fetch()[:,2]\n",
    "I_plus = SIR_plus.solve(n_days-1, n_days).fetch()[:,2]\n",
    "\n",
    "# lag = 6\n",
    "\n",
    "R_opt = SIR_UK.r0 # \n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "plt.plot(t_d,I_UK,'o')\n",
    "plt.plot(t_d, I_opt)\n",
    "plt.plot(t_d, I_minus)\n",
    "plt.plot(t_d, I_plus)\n",
    "plt.legend([\"UK Data\",\"SIR, $R_{0,opt}$ = %.2f\"%R_opt,\"IC_95-\",\"IC_95+\"])\n",
    "plt.title(\"Fitting of the SIR model against 15 days of UK data\")\n",
    "plt.ylabel(\"Number of people infected\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.xlim([min(t_d),max(t_d)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extremely asymmetrical confidence interval for $R_0$ using simple random bootstrap is observed. This occurs most likely because of \n",
    "neglecting the temporal structure of the exponential.\n",
    "\n",
    "To further investigate this phenomena, we can observe the distribution of the $R_0$ parameter on the parameter list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(par_list[:,0]/par_list[:,1], bins=50, density=True, stacked=True)\n",
    "plt.xlabel('$R_0$')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Probability density diagram of $R_0$ bootstrapping\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to observe that the spread is assymetrical towards lower $R_0$ values. This asymmetry is expected owing to the effect of lockdowns and public policies to promote social distancing. A strong assumption of the SIR model is that the spread rate $\\alpha$ and removal rate $\\beta$ are constant, which is not the case in reality specially when strong public policies to limit the spread of a virus take place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance through block cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reliable approach to evaluate the predictive accuracy of a model which variables are time-dependent is to use block cross validation. In Open-SIR, it is implemented through the `model.block_cv` function. The inputs of the model is the minimum sample to use to perform the cross validation. The outputs of the model are lists with the average mean squared error, rolling mean squared error, evolution of the fitted parameters and a `PredictionResults` dataclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We previously imported ci_block_cv which provides a better prediction of the mean squared error of the predictions\n",
    "n_lags=1\n",
    "MSE_avg, MSE_list, p_list, pred_data = SIR_UK.block_cv(lags=n_lags, min_sample=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `pred_data` instance of the `PredictionResults` dataclass offers a simplified syntax to access details of the cross-validation test on model predictions. For instance, the member function `.print_mse()` prints a summary of the mean-squared errors for different forecasts horizons. The number of forecasts horizons provided is by default the length of the observations minus the min_sample parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.print_mse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the residuals between the model and the observed data are normally distributed , the mean squared error is an estimator of the error variance. The member function `.plot_predictions(n_days)` offers a convenient ways to visualize short term predictions with an estimations of the 66% and 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.plot_predictions(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robustness of the model fitting can be explored plotting the change of the parameters during the block cross validation. As the model is fitted with more and more recent data, a measure of robustness is the convergence of the model parameters to a particular value. The list `p_list` contains the information of all model parameters, which can be plotted to assess parameter convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Block cross validation parametric range\")\n",
    "plt.plot(p_list[:,0],'ro')\n",
    "plt.title(\"Variation of the parameter alpha through Block CV\")\n",
    "plt.xlabel(\"Days\", size=14)\n",
    "plt.ylabel(\"alpha\", size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the $\\alpha$ parameter is converging to a value between 0.56 and 0.57 as time progresses. This results have to be reassessed as new data appears, as some fundamental change in the disease epidemiology or social distance may occur suddenly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MSE_avg` list contains the mean squared errors for a forecast of the day $i+1$ since the fitting data ends. For example, the average mean squared error for one day predictions can be accessed on `MSE_avg[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average mean squared error on the time cross validation bootstrapping is: %.3f\" % MSE_avg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to visualize the results of the block cross-validation, is to observe the variation of the reproduction rate $R_0$ and the mean squared error when a subset of the days is taken. By default, `block_cv` starts with the data of three days, fit the model on that data, predicts the number of infected in the next period, calculate the mean squared error between the prediction and the test dataset, and stores it into two arrays. Afterwards, it computes the MSE of 2,3 and up to `len(n_obs)-min_sample` days to be forecasted. It repeats this until it uses the data of $(n-1)$ intervals to predict the $n-th$ latest observation of infections.\n",
    "\n",
    "In the next example, the list of the mean-squared errors for 1-day prediction is visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r0_roll = p_list[:,0]/p_list[:,1]\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t_d[2:], r0_roll,'ro')\n",
    "plt.xlabel(\"Days used in the block to fit parameters\")\n",
    "plt.ylabel(\"Rolling $R_0$\")\n",
    "plt.title(\"Block bootstrapping change in $R_0$\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t_d[(2):-1], MSE_list[0],'bo')\n",
    "plt.xlabel(\"Days used in the block to fit parameters\")\n",
    "plt.ylabel(\"Mean squared error in number of infected\")\n",
    "plt.title(\"Block bootstrapping change in MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it is hard to see any convergence on the change on mean-squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE_lastday = %.2f\" % MSE_list[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean squared error is provided in absolute terms. However, the number of infected cases is increasing with time. \n",
    "\n",
    "The percentage error of the predictions can be calculated directly from the mean squared error. \n",
    "\n",
    "$$\\epsilon(t) = \\frac{\\mathrm{MSE}(t)}{I(t)}$$\n",
    "\n",
    "For example, in the last entry of I_UK, they were 17089 infected, while the MSE was 666.45. Then, the percentage deviation would be:\n",
    "\n",
    "$$\\epsilon(10) = \\frac{22.76}{17089} = 0.13\\%$$ \n",
    "\n",
    "However, this takes model prediction over the accumulated number of cases. Another way to quantify the deviation of the model predictions is to calculate the percentage error over the new infected cases:\n",
    "\n",
    "$$\\epsilon_{\\mathrm{new}}(t) = \\frac{\\mathrm{MSE}(t)}{I(t)-I(t-1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this metric is used, the error naturally will be higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_new = MSE_list[0][-1]/(I_UK[-1]-I_UK[-2])\n",
    "print(\"The percentage error of the SIR model over the last day reported cases is %.1f%%\" % (100*e_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It must be noted that in the last day studied, the error is extremely low owing to an exceptionally good agreement on the last point of the data. Hence, a better estimate of the error in the predictions is to take the average percentage error on the cross validation subset, which considers from day 3 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_avg = np.mean(MSE_list[0]/I_UK[-7:])*100\n",
    "print(\"The average percentage deviation on the number of infected is %.1f%%\" % eps_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize long term predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_time=90\n",
    "SIR_UK.solve(long_time, long_time+1)\n",
    "SIR_UK.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_SIR_fitted.plot()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIR-X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exemplifies how Open-SIR can be used to fit the SIR-X model by [Maier and Dirk (2020)](https://science.sciencemag.org/content/early/2020/04/07/science.abb4557.full) to existing data and make predictions. The SIR-X model is a standard generalization of the Susceptible-Infectious-Removed (SIR) model, which includes the influence of exogenous factors such as policy changes, lockdown of the whole population and quarantine of the infectious individuals.\n",
    "\n",
    "The Open-SIR implementation of the SIR-X model will be validated reproducing the parameter fitting published in the [supplementary material](https://science.sciencemag.org/cgi/content/full/science.abb4557/DC1) of the original article published by [Maier and Brockmann (2020)](https://science.sciencemag.org/content/early/2020/04/07/science.abb4557.full). For simplicity, the validation will be performed only for the city of Guangdong, China."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will source data from the repository of the [John Hopkins University COVID-19 dashboard] (https://coronavirus.jhu.edu/map.html) published formally as a correspondence in [The Lancet](https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30120-1/fulltext#seccestitle10). This time series data contains the number of reported cases $C(t)$ per day for a number of cities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data from John Hokpins university reposotiry\n",
    "# jhu_link = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/who_covid_19_situation_reports/who_covid_19_sit_rep_time_series/who_covid_19_sit_rep_time_series.csv\"\n",
    "jhu_link = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "jhu_df = pd.read_csv(jhu_link)\n",
    "# Explore the dataset\n",
    "jhu_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that the column \"Province/States\" contains the name of the cities, and since the forth column a time series stamp (or index) is provided to record daily data of reported cases. Additionally, there are many days without recorded data for a number of chinese cities. This won't be an issue for parameter fitting as Open-SIR doesn't require uniform spacement of the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "In the following lines, the time series for Guangdong reported cases $C(t)$ is extracted from the original dataframe. Thereafter, the columns are converted to a pandas date time index in order to perform further data preparation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "China = jhu_df[jhu_df[jhu_df.columns[1]]==\"China\"]\n",
    "city_name = \"Guangdong\"\n",
    "city = China[China[\"Province/State\"] == city_name]\n",
    "city = city.drop(columns=[\"Province/State\", \"Country/Region\", \"Lat\",\"Long\"])\n",
    "time_index = pd.to_datetime(city.columns)\n",
    "data = city.values\n",
    "# Visualize the time\n",
    "ts = pd.Series(data = city.values[0], index = time_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function ts.plot() a quick visualization of the dataset is obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_clean = ts.dropna()\n",
    "# Extract data\n",
    "ts_fit = ts_clean['2020-01-21':\"2020-02-12\"]\n",
    "# Convert index to numeric\n",
    "ts_num = pd.to_numeric(ts_fit.index)\n",
    "t0 = ts_num[0]\n",
    "# Convert datetime to days\n",
    "t_days = (ts_num-t0)/(10**9*86400)\n",
    "t_days = t_days.astype(int).values\n",
    "# t_days is an input for SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X number\n",
    "nX = ts_fit.values # Number of infected\n",
    "N = 104.3e6 # Population size of Guangdong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_fit.plot(style='ro')\n",
    "plt.xlabel(\"Number of infected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up SIR and SIR-X models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population $N$ of the city is a necessary input for the model. In this notebook, this was hardocded, but it can be sourced directly from a web source.\n",
    "\n",
    "Note that whilst the SIR model estimates directly the number of infected people, $N I(t)$, SIR-X estimates the number of infected people based on the number of tested cases that are in quarantine or in an hospital $N X(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines are required only if opensir wasn't installed using pip install, or if opensir is running in the pipenv virtual environment\n",
    "import sys\n",
    "path_opensir = '../../'\n",
    "sys.path.append(path_opensir)\n",
    "\n",
    "# Import SIR and SIRX models\n",
    "from opensir.models import SIR, SIRX\n",
    "nX = ts_fit.values # Number of observed infections of the time series\n",
    "N = 104.3e6 # Population size of Guangdong\n",
    "params = [0.95, 0.38]\n",
    "w0 = (N-nX[0], nX[0], 0)\n",
    "\n",
    "G_sir = SIR()\n",
    "G_sir.set_params(p=params, initial_conds=w0)\n",
    "G_sir.fit_input=2\n",
    "G_sir.fit(t_days, nX)\n",
    "G_sir.solve(t_days[-1], t_days[-1]+1)\n",
    "t_SIR = G_sir.fetch()[:,0]\n",
    "I_SIR = G_sir.fetch()[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to fit a SIR model to Guangdong data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize= 14 )\n",
    "plt.plot(t_SIR, I_SIR)\n",
    "plt.plot(t_days, nX, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SIR model is clearly not appropriate to fit this data, as it cannot resolve the effect of exogeneous containment efforts such as quarantines or lockdown. We will repeat the process with a SIR-X model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sirx = SIRX()\n",
    "params = [6.2/8, 1/8, 0.05, 0.05, 5]\n",
    "# X_0 can be directly ontained from the statistics\n",
    "n_x0 = nX[0]            # Number of people tested positive\n",
    "n_i0 = nX[0]\n",
    "\n",
    "w0 = (N-n_x0-n_i0, n_i0, 0, n_x0)\n",
    "g_sirx.set_params(p=params, initial_conds=w0)\n",
    "# Fit all parameters\n",
    "fit_index=[False, False, True, True, True]\n",
    "g_sirx.fit(t_days, nX, fit_index = fit_index)\n",
    "g_sirx.solve(t_days[-1], t_days[-1]+1)\n",
    "t_sirx = g_sirx.fetch()[:,0]\n",
    "inf_sirx = g_sirx.fetch()[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,6])\n",
    "ax = plt.axes()\n",
    "plt.plot(t_sirx, inf_sirx, 'b-', linewidth=2)\n",
    "plt.plot(t_SIR, I_SIR,'g-', linewidth=2)\n",
    "plt.plot(t_days, nX, 'ro')\n",
    "plt.legend([\"SIR-X model fit\", \"SIR model fit\", \"Number of reported cases\"], fontsize=13)\n",
    "plt.title(\"SARS-CoV-2 evolution in Guangdong, China\", size=15)\n",
    "plt.xlabel('Days', fontsize=14)\n",
    "plt.ylabel('COVID-19 confirmed cases', fontsize=14)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the parameters, the effective infectious period $T_{I,eff}$ and the effective reproduction rate $R_{0,eff}$ can be obtained from the model properties\n",
    "\n",
    "$$T_{I,eff} = (\\beta + \\kappa + \\kappa_0)^{-1}$$\n",
    "$$R_{0,eff} = \\alpha T_{I,eff}$$\n",
    "\n",
    "Aditionally, the Public containment leverage $P$ and the quarantine probability $Q$ can be calculated through:\n",
    "\n",
    "$$P = \\frac{\\kappa_0}{\\kappa_0 + \\kappa}$$\n",
    "$$Q = \\frac{\\kappa_0 + \\kappa}{\\beta + \\kappa_0 + \\kappa}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Effective infectious period T_I_eff =  %.2f days \" % g_sirx.t_inf_eff )\n",
    "print(\"Effective reproduction rate R_0_eff =  %.2f, Maier and Brockmann = %.2f\" % (g_sirx.r0_eff, 3.02))\n",
    "print(\"Public containment leverage =  %.2f, Maier and Brockmann = %.2f\" % (g_sirx.pcl, 0.75))\n",
    "print(\"Quarantine probability =  %.2f, Maier and Brockmann = %.2f\" % (g_sirx.q_prob, 0.51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of predictive confidence intervals\n",
    "\n",
    "The confidence intervals on the predictions of the SIR-X model can be calculated using a block cross validation. This technique is widely used in Time Series Analysis. In the open-sir API, the function `model.ci_block_cv` calculates the average mean squared error of the predictions, a list of the rolling mean squared errors and the list of parameters which shows how much each parameter changes taking different number of days for making predictions.\n",
    "\n",
    "The three first parameters are the same as the fit function, while the last two parameters are the `lags` and the `min_sample`. The `lags` parameter indicates how many periods in the future will be forecasted in order to calculate the mean squared error of the model prediction. The `min_sample` parameter indicates the initial number of observations and days that will be taken to perform the block cross validation.\n",
    "\n",
    "In the following example, `model.ci_block_cv` is used to estimate the average mean squared error of *1-day* predictions taking *6* observations as the starting point of the cross validation. For Guangdong, a `min_sample=6` higher than the default 3 is required to handle well the missing data. This way, both the data on the four first days, and two days after the data starts again, are considered for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence intervals\n",
    "mse_avg, mse_list, p_list, pred_data = g_sirx.block_cv(lags = 1, min_sample = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is assumed that the residuals distribute normally, then a good estimation of a 95% confidence interval on the one-day prediction of the number of confirmed cases is \n",
    "\n",
    "$$\\sigma \\sim \\mathrm{MSE} \\rightarrow n_{X,{t+1}} \\sim \\hat{n}_{X,{t+1}} \\pm 2 \\sigma$$ \n",
    "\n",
    "Where $n_{X,{t+1}}$ is the real number of confirmed cases in the next day, and $\\hat{n}_{X,{t+1}}$ is the estimation using the SIR-X model using cross validation. We can use the `PredictionResults` instance `pred_data` functionality to explore the mean-squared errors and the predictions confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.print_mse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive accuracy of the model is quite impressive, even for 9-day predictions. Let's take advantage of the relatively low mean squared error to forecast a 10 days horizon with confidence intervals using `pred_data.plot_predictions(n_days=9)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_data.plot_predictions(n_days=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is assumed that the residuals distribute normally, then a good estimation of a 95% confidence interval on the one-day prediction of the number of confirmed cases is \n",
    "\n",
    "$$\\sigma \\sim \\mathrm{MSE} \\rightarrow n_{X,{t+1}} \\sim \\hat{n}_{X,{t+1}} \\pm 2 \\sigma$$ \n",
    "\n",
    "Where $n_{X,{t+1}}$ is the real number of confirmed cases in the next day, and $\\hat{n}_{X,{t+1}}$ is the estimation using the SIR-X model using cross validation. We use solve to make a 1-day prediction and append the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "g_sirx.solve(t_days[-1]+1,t_days[-1]+2)\n",
    "n_X_tplusone = g_sirx.fetch()[-1,4]\n",
    "print(\"Estimation of n_X_{t+1} = %.0f +- %.0f \" % (n_X_tplusone, 2*mse_avg[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform parameter list into a DataFrame\n",
    "par_block_cv = pd.DataFrame(p_list)\n",
    "# Rename dataframe columns based on SIR-X parameter names\n",
    "par_block_cv.columns = g_sirx.PARAMS\n",
    "# Add the day. Note that we take the days from min_sample until the end of the array, as days\n",
    "# 0,1,2 are used for the first sampling in the block cross-validation\n",
    "par_block_cv['Day'] = t_days[5:]\n",
    "# Explore formatted dataframe for parametric analysis\n",
    "par_block_cv.head(len(p_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = [5,5])\n",
    "ax = plt.axes()\n",
    "ax.tick_params(axis = \"both\", which = \"major\", labelsize = 14 )\n",
    "plt.plot(mse_list[0],'ro')\n",
    "plt.xlabel('Number of days used to predict the next day', size = 14)\n",
    "plt.ylabel('MSE', size = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an outlier on day 1, as this is when the missing date starts. A more reliable approach would be to take the last 8 values of the mean squared error to calculate a new average assuming that there will be no more missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation of fitted parameters\n",
    "\n",
    "Finally, it is possible to observe how the model parameters change as more days and number of confirmed cases are introduced in the block cross validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear to observe that after day 15 all parameters except kappa begin to converge. Therefore, care must be taken when performing inference over the parameter kappa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long term prediction\n",
    "Now we can use the model to predict when the peak will occur and what will be the maximum number of infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "plt.figure(figsize=[6,6])\n",
    "ax = plt.axes()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize= 14 )\n",
    "g_sirx.solve(40,41)\n",
    "# Plot\n",
    "plt.plot(g_sirx.fetch()[:,4], 'b-', linewidth=2) # X(t)\n",
    "plt.plot(g_sirx.fetch()[:,2], 'b--', linewidth=2) # I(t)\n",
    "plt.xlabel('Day', size=14)\n",
    "plt.ylabel('Number of people', size=14)\n",
    "plt.legend([\"X(t): Confirmed\",\"I(t) = Infected\"], fontsize=13)\n",
    "plt.title(city_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained with a limited amount of data. It is clear to observe that since the measures took place in Guangdong, at least 6 weeks of quarantine were necessary to control the pandemics. Note that a limitation of this model is that it predicts an equilibrium where the number of infected, denoted by the yellow line in the figure above, is 0 after a short time. In reality, this amount will decrease to a small number.\n",
    "\n",
    "After the peak of infections is reached, it is necessary to keep the quarantine and effective contact tracing for at least 30 days more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate using model.plot()\n",
    "\n",
    "The function `model.plot()` offers a handy way to visualize model fitting and predictions. Custom visualizations can be validated against the `model.plot()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g_sirx.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the values of the number of infected and quarantined individuals, as well as the time of the peak, it is clear that both plots are in good agreement, which validates the customized plot created by the code cell below \"long term prediction\"."
   ]
 }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

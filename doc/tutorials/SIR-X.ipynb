{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIR-X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exemplifies how Open-SIR can be used to fit the SIR-X model by [Maier and Dirk (2020)](https://science.sciencemag.org/content/early/2020/04/07/science.abb4557.full) to existing data and make predictions. The SIR-X model is a standard generalization of the Susceptible-Infectious-Removed (SIR) model, which includes the influence of exogenous factors such as policy changes, lockdown of the whole population and quarantine of the infectious individuals.\n",
    "\n",
    "The Open-SIR implementation of the SIR-X model will be validated reproducing the parameter fitting published in the [supplementary material](https://science.sciencemag.org/cgi/content/full/science.abb4557/DC1) of the original article published by [Maier and Brockmann (2020)](https://science.sciencemag.org/content/early/2020/04/07/science.abb4557.full). For simplicity, the validation will be performed only for the city of Guangdong, China."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will source data from the repository of the [John Hopkins University COVID-19 dashboard] (https://coronavirus.jhu.edu/map.html) published formally as a correspondence in [The Lancet](https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(20)30120-1/fulltext#seccestitle10). This time series data contains the number of reported cases $C(t)$ per day for a number of cities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data from John Hokpins university reposotiry\n",
    "jhu_link = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/who_covid_19_situation_reports/who_covid_19_sit_rep_time_series/who_covid_19_sit_rep_time_series.csv\"\n",
    "jhu_df = pd.read_csv(jhu_link)\n",
    "# Explore the dataset\n",
    "jhu_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that the column \"Province/States\" contains the name of the cities, and since the forth column a time series stamp (or index) is provided to record daily data of reported cases. Additionally, there are many days without recorded data for a number of chinese cities. This won't be an issue for parameter fitting as Open-SIR doesn't require uniform spacement of the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "In the following lines, the time series for Guangdong reported cases $C(t)$ is extracted from the original dataframe. Thereafter, the columns are converted to a pandas date time index in order to perform further data preparation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "China = jhu_df[jhu_df[jhu_df.columns[1]]==\"China\"]\n",
    "city_name = \"Guangdong\"\n",
    "city = China[China[\"Province/States\"] == city_name]\n",
    "city = city.drop(columns=[\"Province/States\", \"Country/Region\", \"WHO region\",])\n",
    "time_index = pd.to_datetime(city.columns)\n",
    "data = city.values\n",
    "# Visualize the time\n",
    "ts = pd.Series(data = city.values[0], index = time_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function ts.plot() a quick visualization of the dataset is obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_clean = ts.dropna()\n",
    "# Extract data\n",
    "ts_fit = ts_clean['2020-01-21':\"2020-02-12\"]\n",
    "# Convert index to numeric\n",
    "ts_num = pd.to_numeric(ts_fit.index)\n",
    "t0 = ts_num[0]\n",
    "# Convert datetime to days\n",
    "t_days = (ts_num-t0)/(10**9*86400)\n",
    "t_days = t_days.astype(int).values\n",
    "# t_days is an input for SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X number\n",
    "nX = ts_fit.values # Number of infected\n",
    "N = 104.3e6 # Population size of Guangdong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_fit.plot(style='ro')\n",
    "plt.xlabel(\"Number of infected\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing data between the 25th of January and the 31st of January doesn't prevent to fit the SIR-X model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up SIR and SIR-X models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population $N$ of the city is a necessary input for the model. In this notebook, this was hardocded, but it can be sourced directly from a web source.\n",
    "\n",
    "Note that whilst the SIR model estimates directly the number of infected people, $N I(t)$, SIR-X estimates the number of infected people based on the number of tested cases that are in quarantine or in an hospital $N X(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines are required only if opensir wasn't installed using pip install, or if opensir is running in the pipenv virtual environment\n",
    "import sys\n",
    "path_opensir = '../../'\n",
    "sys.path.append(path_opensir)\n",
    "\n",
    "# Import SIR and SIRX models\n",
    "from opensir.models import SIR, SIRX\n",
    "nX = ts_fit.values # Number of observed infections of the time series\n",
    "N = 104.3e6 # Population size of Guangdong\n",
    "params = [0.95, 0.38]\n",
    "w0 = (N-nX[0], nX[0], 0)\n",
    "\n",
    "G_sir = SIR()\n",
    "G_sir.set_params(p=params, initial_conds=w0)\n",
    "G_sir.fit_input=2\n",
    "G_sir.fit(t_days, nX, N)\n",
    "G_sir.solve(t_days[-1], t_days[-1]+1)\n",
    "t_SIR = G_sir.fetch()[:,0]\n",
    "I_SIR = G_sir.fetch()[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_SIR, I_SIR)\n",
    "plt.plot(t_days, nX, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SIR model is clearly not appropriate to fit this data. We will repeat the process with a SIR-X model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sirx = SIRX()\n",
    "params = [6.2/8, 1/8, 0.05, 0.05, 5]\n",
    "# X_0 can be directly ontained from the statistics\n",
    "n_x0 = nX[0]            # Number of people tested positive\n",
    "n_i0 = nX[0]\n",
    "\n",
    "w0 = (N-n_x0-n_i0, n_i0, 0, n_x0)\n",
    "g_sirx.set_params(p=params, initial_conds=w0)\n",
    "# Fit all parameters\n",
    "fit_index=[False, False, True, True, True]\n",
    "g_sirx.fit(t_days, nX, N, fit_index = fit_index)\n",
    "g_sirx.solve(t_days[-1], t_days[-1]+1)\n",
    "t_sirx = g_sirx.fetch()[:,0]\n",
    "inf_sirx = g_sirx.fetch()[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,6])\n",
    "ax = plt.axes()\n",
    "plt.plot(t_sirx, inf_sirx, 'b-', linewidth=2)\n",
    "plt.plot(t_SIR, I_SIR,'g-', linewidth=2)\n",
    "plt.plot(t_days, nX, 'ro')\n",
    "plt.legend([\"SIR-X model fit\", \"SIR model fit\", \"Number of reported cases\"], fontsize=13)\n",
    "plt.title(\"SARS-CoV-2 evolution in Guangdong, China\", size=15)\n",
    "plt.xlabel('Days', fontsize=14)\n",
    "plt.ylabel('COVID-19 confirmed cases', fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the parameters, the effective infectious period $T_{I,eff}$ and the effective reproduction rate $R_{0,eff}$ can be obtained from the model properties\n",
    "\n",
    "$$T_{I,eff} = (\\beta + \\kappa + \\kappa_0)^{-1}$$\n",
    "$$R_{0,eff} = \\alpha T_{I,eff}$$\n",
    "\n",
    "Aditionally, the Public containment leverage $P$ and the quarantine probability $Q$ can be calculated through:\n",
    "\n",
    "$$P = \\frac{\\kappa_0}{\\kappa_0 + \\kappa}$$\n",
    "$$Q = \\frac{\\kappa_0 + \\kappa}{\\beta + \\kappa_0 + \\kappa}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Effective infectious period T_I_eff =  %.2f days \" % g_sirx.t_inf_eff )\n",
    "print(\"Effective reproduction rate R_0_eff =  %.2f, Maier and Brockmann = %.2f\" % (g_sirx.r0_eff, 3.02))\n",
    "print(\"Public containment leverage =  %.2f, Maier and Brockmann = %.2f\" % (g_sirx.pcl, 0.75))\n",
    "print(\"Quarantine probability =  %.2f, Maier and Brockmann = %.2f\" % (g_sirx.q_prob, 0.51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of predictive confidence intervals\n",
    "\n",
    "The confidence intervals on the predictions of the SIR-X model can be calculated using a block cross validation. This technique is widely used in Time Series Analysis. In the open-sir API, the function `model.ci_block_cv` calculates the average mean squared error of the predictions, a list of the rolling mean squared errors and the list of parameters which shows how much each parameter changes taking different number of days for making predictions.\n",
    "\n",
    "The three first parameters are the same as the fit function, while the last two parameters are the `lags` and the `min_sample`. The `lags` parameter indicates how many periods in the future will be forecasted in order to calculate the mean squared error of the model prediction. The `min_sample` parameter indicates the initial number of observations and days that will be taken to perform the block cross validation.\n",
    "\n",
    "In the following example,`model.ci_block_cv` is used to estimate the average mean squared error of *1-day* predictions taking *3* observations as the starting point of the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence intervals\n",
    "mse_avg, mse_list, p_list = g_sirx.ci_block_cv(t_days, nX, N, lags = 1, min_sample=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! let's print the average mean squared error (MSE) for one-day predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One day estimation of the mean squared error of SIR-X fitted to Guangdong Data = %.0f\" % mse_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is assumed that the residuals distribute normally, then a good estimation of a 95% confidence interval on the one-day prediction of the number of confirmed cases is \n",
    "\n",
    "$$\\sigma \\sim \\mathrm{MSE} \\rightarrow n_{X,{t+1}} \\sim \\hat{n}_{X,{t+1}} \\pm 2 \\sigma$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $n_{X,{t+1}}$ is the real number of confirmed cases in the next day, and $\\hat{n}_{X,{t+1}}$ is the estimation using the SIR-X model using cross validation. We use solve to make a 1-day prediction and append the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'g_sirx' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b09b1c0fb50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mg_sirx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_days\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mn_X_tplusone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg_sirx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Estimation of n_X_{t+1} = %.0f +- %.0f \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_X_tplusone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmse_avg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g_sirx' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "g_sirx.solve(t_days[-1]+1,t_days[-1]+2)\n",
    "n_X_tplusone = g_sirx.fetch()[-1,4]\n",
    "print(\"Estimation of n_X_{t+1} = %.0f +- %.0f \" % (n_X_tplusone, 2*mse_avg) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the model seems to fit far better than this estimation. Fortunately, it is possible to explore the residuals of the block cross validation through the mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-48e168c99f9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Number of days used to predict the next day'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MSE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=[4,4])\n",
    "plt.plot(mse_list,'ro')\n",
    "plt.xlabel('Number of days used to predict the next day')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an outlier on day 1, as this is when the missing date starts. A more reliable approach would be to take the last 8 values of the mean squared error to calculate a new average assuming that there will be no more missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_missing_values_MSE = np.mean(mse_list[-8:])\n",
    "print(\"New MSE = %.1f\" % after_missing_values_MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which provides a value that is more aligned with the spread observed in the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "g_sirx.solve(t_days[-1]+1,t_days[-1]+2)\n",
    "n_X_tplusone = g_sirx.fetch()[-1,4]\n",
    "print(\"Estimation of n_X_{t+1} = %.0f +- %.0f \" % (n_X_tplusone, 2*after_missing_values_MSE) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation of fitted parameters\n",
    "\n",
    "Finally, it is possible to observe how the model parameters change as more days and number of confirmed cases are introduced in the block cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform parameter list into a DataFrame\n",
    "par_block_cv = pd.DataFrame(p_list)\n",
    "# Rename dataframe columns based on SIR-X parameter names\n",
    "par_block_cv.columns = g_sirx.PARAMS\n",
    "# Add the day. Note that we take the days from min_sample until the end of the array, as days\n",
    "# 0,1,2 are used for the first sampling in the block cross-validation\n",
    "par_block_cv['Day'] = t_days[3:]\n",
    "# Explore formatted dataframe for parametric analysis\n",
    "par_block_cv.head(len(p_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear to observe that after day 5 all parameters except kappa begin to converge. Therefore, care must be taken when performing inference over the parameter kappa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long term prediction\n",
    "Now we can use the model to predict when the peak will occur and what will be the maximum number of infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "plt.figure(figsize=[6,6])\n",
    "ax = plt.axes()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize= 14 )\n",
    "g_sirx.solve(40,41)\n",
    "# Plot\n",
    "plt.plot(g_sirx.fetch()[:,4], 'b-', linewidth=2) # X(t)\n",
    "plt.plot(g_sirx.fetch()[:,2], 'b--', linewidth=2) # I(t)\n",
    "plt.xlabel('Day', size=14)\n",
    "plt.ylabel('Number of people', size=14)\n",
    "plt.legend([\"X(t): Confirmed\",\"I(t) = Infected\"], fontsize=13)\n",
    "plt.title(city_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained with a limited amount of data. It is clear to observe that since the measures took place in Guangdong, at least 6 weeks of quarantine were necessary to control the pandemics. Note that a limitation of this model is that it predicts an equilibrium where the number of infected, denoted by the yellow line in the figure above, is 0 after a short time. In reality, this amount will decrease to a small number.\n",
    "\n",
    "After the peak of infections is reached, it is necessary to keep the quarantine and effective contact tracing for at least 30 days more."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}